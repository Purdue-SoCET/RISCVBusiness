# RISC-V Vector Extension Project Overview

## Introduction

This project involves the integration of the RISC-V "V" Vector Extension into SoCET's RISC-V core. The primary goal of this project is to implement all instructions in the Zve32x standard vector extension such that the processor is able to run vectorized code generated by standard compilers such as Clang or GCC with a significant performance uplift over the base processor in parallelizable applications. This has to be done while keeping area and power in check, and while ensuring that the design is verifiable, maintainable, and extendable by SoCET moving forward.


## Background

The RISC-V "V" Vector Extension (henceforth referred to as "RVV") is a new RISC-V spec that adds vector processing capability to the base ISA. It introduces instructions for performing integer, fixed point, and floating point operations on vectors of elements of up to 64 bits each. This extension uses an interesting approach to handling vector lengths, somewhat similar to Arm's SVE. The vector lengths are dynamically computed at runtime based on the hardware's vector register size and execution capabilities instead of being fixed as they are in "traditional" vector ISAs such as AVX and NEON. This, along with automatic masking of tail elements when the vector length is smaller than a vector register, makes writing vector code really easy for assembly programmers and compiler writers. However, this does mean that the hardware is responsible for dealing with a lot of the bookkeeping, which adds complexity to the design and makes our lives significantly harder.

The spec defines a set of standard vector extensions, out of which we intend to implement the Zve32x extension. This extension requires support for a maximum element size of 32 bits, and requires implementing all vector instructions other than floating point instructions as well as precise traps. Later, we could also look into implementing the Zve32f extension, which adds support for floating point instructions but is otherwise the same.


## Architecture

Below is a high-level overview of our proposed pipeline architecture.

![https://purdue0-my.sharepoint.com/:i:/g/personal/faloufi_purdue_edu/Ef7fWtYU905GmUMDZQX-fGQBWvvj4wjClwcanZbLCJL1uA?e=JSMnIU](https://purdue0-my.sharepoint.com/:i:/g/personal/faloufi_purdue_edu/Ef7fWtYU905GmUMDZQX-fGQBWvvj4wjClwcanZbLCJL1uA?e=JSMnIU)

The architecture is largely derived from the 3-stage pipeline used on AFTx07, with the major addition of a uop queue in between the instruction decode and execute logic. This allows us to split long vector operations into smaller uops that can be natively executed by our 4-wide vector execute stage. All instructions whether scalar or vector share the pipeline and stay strictly in order to minimize complexity. The load store controller serializes accesses to the cache to allow us to handle wide vector operations with our single-ported cache. We add a shadow copy of the vector CSRs in the decode stage to ensure that changes made by `vset*` instructions get immediately reflected in the vector instructions following them without requiring a stall. The shadow copy is overwritten by the primary CSRs in the mem stage whenever there is a pipeline flush.

The design uses a 128-bit wide vector register file split into 4 32-bit wide banks. Each bank is coupled with a single vector execution lane which is capable of performing various vector operations at a native width of 32 bits. To support sub-word and mixed-width operations, each vector execution lane includes so-called alignment units that will shift and mask the data coming from and going to the vector register files to allow reuse of the native-width functional units.

## Software

We have verified that we are able to generate vectorized code using the latest version of Clang/LLVM. GCC is in the process of adding auto-vectorization support for RVV, but the changes have not been merged into the mainline releases as of the end of 2023. We are able to compile Embench using Clang and see that a good number of vector instructions are generated, which indicates that we should be able to see a reasonable performance uplift in Embench.

In addition, compiler support means that anyone writing code for our SoC will be able to enjoy the benefits of vector acceleration by simply setting the appropriate compiler flags, and will not need to explicitly think about writing vectorized code.

## Future Plans

The following is our target for the end of Spring 2024:
- All Zve32x instructions either implemented or handled by trap-and-emulate
- Design verified and integrated into the mainline source for AFTx08 or beyond
- Performance evaluation relative to the base 3-stage pipeline

The following are goals that could be pursued as time permits:
- Add fast path for unit-strided load/stores that reads or writes the entire cache line in one cycle
- Pipeline heavyweight functional units such as multiply/divides and move them after the mem stage to reduce hazards
- Add hardware support for instructions that are currently trapped and emulated such as fixed point arithmetic
- Optimize the memory subsystem for matching the bandwidth needs of the vector extension

## Contributors

- Fahad Aloufi (faloufi@purdue.edu)
- Max Michalec (michalem@purdue.edu)
- Om Gupta (guptao@purdue.edu)
